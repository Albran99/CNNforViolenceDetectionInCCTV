{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNG34LQUbPT+2pTurTVt2UV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Crop an image to remove black bars around the scene.\n","\n","Parameters:\n","- image (numpy.ndarray): Input image to be cropped.\n","- y_nonzero (numpy.ndarray or None): Array containing row indices of nonzero values.\n","- x_nonzero (numpy.ndarray or None): Array containing column indices of nonzero values.\n","\n","Returns:\n","* tuple: A tuple containing:\n","  * numpy.ndarray: Cropped image with black bars removed.\n","  * numpy.ndarray: Row indices of nonzero values.\n","  * numpy.ndarray: Column indices of nonzero values.\n","\n","This function crops an input image to remove black bars surrounding the scene.\n","The cropping is based on the regions where the pixel values exceed a certain brightness threshold.\n","This helps in stabilizing videos and improves training performance by preventing flickering and noise.\n","\n","The cropping process is performed only on the first frame of a frame burst to ensure consistency across the video.\n","If the indices of nonzero values (y_nonzero and x_nonzero) are not provided,\n","the function calculates them using a grayscale version of the input image and a brightness threshold of 1.\n","\n","The cropped image is obtained by slicing the original image using the minimum and maximum indices of nonzero values\n","along rows and columns. The function returns the cropped image along with the corresponding row and column indices,\n","which can be used for cropping subsequent frames in a video burst."],"metadata":{"id":"5Ep-bR_GOUH8"}},{"cell_type":"code","source":["# Crop an image to remove black bars around the scene\n","def crop(image, y_nonzero, x_nonzero):\n","  # The calculation of which columns and rows have to be removed should be done\n","  # only with the first frame of a frame burst\n","  # This prevents a very subtle and rare bug in which a video 'flickers', due to the noise\n","  # In this way, videos are more stable, which in turns improves training performance\n","  if y_nonzero is None or x_nonzero is None:\n","    # We use a gray scaled version of the image to obtain all rows and columns\n","    # containing pixels with a brightness over a certain threshold\n","    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    # On a scale [0-255], a threshold of 1 is enough to remove all black bars\n","    # without removing important information, especially on very dark or nightly images\n","    brightness_threshold = 1\n","    y_nonzero, x_nonzero = np.where(gray_image > brightness_threshold)\n","  # A slice of the original image is returned containing only\n","  # rows and columns of pixels with relevant information\n","  # We also have to return the rows and column indeces to be used on all subsequent frames in the video burst\n","  return image[np.min(y_nonzero):np.max(y_nonzero), np.min(x_nonzero):np.max(x_nonzero)], y_nonzero, x_nonzero"],"metadata":{"id":"pvwRfwLAMoZl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`load_and_preprocess_video` takes the path to a video file and a configuration dictionary as input. It then extracts frames from the video file, preprocesses them according to the provided configurations, and returns a list of numpy arrays containing the processed frames."],"metadata":{"id":"PUsNhqcPfTdg"}},{"cell_type":"code","source":["# Function to load and preprocess video frames with a fixed number of frames\n","def load_and_preprocess_video(video_path, pkl_config):\n","  # We use the library ComputerVision2 to read video files and extract relevant frames\n","  cap = cv2.VideoCapture(video_path)\n","  # The declared fps by the video file often doesn't correspond with the effective video information\n","  # Probably due to subsequent re-encoding by the dataset provider, many videos\n","  # have more frames than the original source, bringing the problem of repeated frames\n","  declared_fps = int(cap.get(cv2.CAP_PROP_FPS ))\n","  try:\n","    # We calculate how many sets of frames (a.k.a. frame bursts) containing 'FRAMES' frames\n","    # we can extarct from the video, assuming a certain FPS\n","    frame_factor = declared_fps / pkl_config['FPS']\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) / frame_factor\n","    number_of_sets = (int)(total_frames // pkl_config['FRAMES'])\n","  except:\n","    # Sometimes the file doesn't provide a video fps\n","    # This may lead to a DivBy0 Error. We cannot recover from this\n","    cap.release()\n","    return []\n","\n","  frame_sets = []\n","  for fset in range(number_of_sets):\n","    # Calculate frame indices to extract equidistant frames\n","    frame_indices = np.linspace(pkl_config['FRAMES'] * fset, pkl_config['FRAMES'] * (fset + 1), pkl_config['FRAMES'], dtype=int)\n","    frames = []\n","    # Initially set to None to perform the cropping calculation only on the first frame of each burst\n","    y_nonzero, x_nonzero = None, None\n","    for idx in frame_indices:\n","      # Extarct a frame from the video\n","      cap.set(cv2.CAP_PROP_POS_FRAMES, idx*frame_factor)\n","      ret, frame = cap.read()\n","      if not ret:\n","          # Some videos have variable frame rates. The read might fail\n","          break\n","      if pkl_config['CROP']:\n","        frame, y_nonzero, x_nonzero = crop(frame, y_nonzero, x_nonzero) # prevent flickering\n","      frame = cv2.resize(frame, (pkl_config['SIZE'], pkl_config['SIZE']))\n","      frames.append(frame)\n","\n","    frames = np.array(frames)\n","    # Filter frames only having the specified shape\n","    if frames.shape == (pkl_config['FRAMES'], pkl_config['SIZE'], pkl_config['SIZE'], 3):\n","      if pkl_config['FRAMES'] == 1: # allows for 2dCNNs\n","        frame_sets.append(frames[0]) # only return the frame instead of a burst of 1 frame\n","      else:\n","        frame_sets.append(frames) # append the burst of frames\n","  cap.release()\n","  return frame_sets # a (possibly empty) array of numpy arrays in shape"],"metadata":{"id":"q06P783fMsG7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load and preprocess video frames with a fixed number of frames.\n","\n","Parameters:\n","- video_path (str): Path to the video file.\n","- pkl_config (dict): Dictionary containing configuration parameters for preprocessing.\n","\n","Returns:\n","- list: A list containing numpy arrays representing sets of preprocessed video frames.\n","\n","This function loads and preprocesses video frames from the specified video file.\n","It extracts frames at equidistant intervals to form sets of frames (frame bursts) with a fixed number of frames defined by 'pkl_config['FRAMES']'.\n","\n","The function uses OpenCV (cv2) to read the video file. It calculates the effective frames per second (FPS) of the video to handle videos with variable frame rates.\n","\n","The preprocessing includes optional cropping of frames to remove black bars around the scene, which helps in preventing flickering.\n","The cropping calculation is performed only on the first frame of each burst to ensure stability across the video.\n","\n","Each frame is resized to the dimensions specified in 'pkl_config['SIZE']'.\n","The function filters frames based on the specified shape and returns sets of preprocessed frames as numpy arrays.\n","\n","If the video file does not provide FPS information, the function returns an empty list.\n","\n","Note: This function assumes that the input video is in color (RGB)."],"metadata":{"id":"az3pdznbOgfN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5eJl754NMa81"},"outputs":[],"source":["# Function to create a dataset of videos with corresponding labels if not already present\n","def create_video_dataset(dataset_path, pkl_config, pickle_name):\n","\n","    train_data = []\n","    train_labels = []\n","    test_data = []\n","    test_labels = []\n","\n","    pickles_dir = f'{ROOT_PATH}/pickles'\n","\n","    train_data_pkl_filepath = f'{pickles_dir}/{pickle_name}-train_data.pkl'\n","    train_label_pkl_filepath = f'{pickles_dir}/{pickle_name}-train_labels.pkl'\n","    test_data_pkl_filepath = f'{pickles_dir}/{pickle_name}-test_data.pkl'\n","    test_label_pkl_filepath = f'{pickles_dir}/{pickle_name}-test_labels.pkl'\n","    try: # don't create the pickle files if they are already present\n","      with open(train_data_pkl_filepath, 'rb') as trd, open(train_label_pkl_filepath, 'rb') as trl, open(test_data_pkl_filepath, 'rb') as ted, open(test_label_pkl_filepath, 'rb') as tel:\n","        train_data = pickle.load(trd)\n","        train_labels = pickle.load(trl)\n","        test_data = pickle.load(ted)\n","        test_labels = pickle.load(tel)\n","      print(\"extracted from cached pickles\")\n","    except FileNotFoundError: # files are missing: create them\n","      dirs = os.listdir(dataset_path)\n","      dirs.append('fight-detection-surv-dataset-master/fight')\n","      dirs.append('fight-detection-surv-dataset-master/noFight')\n","      dirs.remove('fight-detection-surv-dataset-master')\n","      assert len(dirs) == 5\n","      print(f\"loading dataset {dataset_path} {dirs}\")\n","\n","      labelled_video_paths = []\n","      # Collect every video inside all directories\n","      for dir in tqdm(dirs, desc=\"all dirs\"):\n","          dir = os.path.join(dataset_path, dir)\n","          for f in os.listdir(dir):\n","            if f.endswith('.mp4') or f.endswith('.mov'):\n","              # The first letter of a non-violence video filename is always 'n'\n","              labelled_video_paths.append((os.path.join(dir, f), 0 if 'n' == f[0] else 1))\n","\n","      # All videos are shuffled to prevent cutting out always the same source when rebalancing\n","      random.shuffle(labelled_video_paths)\n","      labelled_frame_sets = [[], []] # [[non-violence], [violence]]\n","      count_files = len(labelled_video_paths)\n","      for video_path, label in tqdm(labelled_video_paths, desc=\"all labelled_video_paths\"):\n","          # We parse each video to extract the maximum amount of frame bursts as we can\n","          labelled_frame_sets[label].extend(load_and_preprocess_video(video_path, pkl_config))\n","\n","      violence_amount = len(labelled_frame_sets[1])\n","      non_violence_amount = len(labelled_frame_sets[0])\n","      print(f\"extracted ({violence_amount = })+({non_violence_amount = }) = {violence_amount + non_violence_amount} frame sets from {len(labelled_video_paths)} videos\")\n","      # We rebalance the dataset to get the same number of violence and non-violence videos\n","      min_amount = min(violence_amount, non_violence_amount)\n","      # Remove from array without making a copy\n","      labelled_frame_sets[0][min_amount:] = []\n","      labelled_frame_sets[1][min_amount:] = []\n","\n","      # We use the TRAIN_SPLIT parameter to create two independent datasets for training and testing\n","      train_data = labelled_frame_sets[0][:(int)(pkl_config['TRAIN_SPLIT']*min_amount)] + labelled_frame_sets[1][:(int)(pkl_config['TRAIN_SPLIT']*min_amount)]\n","      train_labels = ([0] * min_amount)[:(int)(pkl_config['TRAIN_SPLIT']*min_amount)] + ([1] * min_amount)[:(int)(pkl_config['TRAIN_SPLIT']*min_amount)]\n","      test_data = labelled_frame_sets[0][(int)(pkl_config['TRAIN_SPLIT']*min_amount):] + labelled_frame_sets[1][(int)(pkl_config['TRAIN_SPLIT']*min_amount):]\n","      test_labels = ([0] * min_amount)[(int)(pkl_config['TRAIN_SPLIT']*min_amount):] + ([1] * min_amount)[(int)(pkl_config['TRAIN_SPLIT']*min_amount):]\n","      # no need to shuffle those arrays, as it is already done inside batch scheduling during model fitting\n","\n","      train_data = np.array(train_data)\n","      train_labels = np.array(train_labels)\n","      test_data = np.array(test_data)\n","      test_labels = np.array(test_labels)\n","\n","      with open(train_data_pkl_filepath, 'wb') as trd, open(train_label_pkl_filepath, 'wb') as trl, open(test_data_pkl_filepath, 'wb') as ted, open(test_label_pkl_filepath, 'wb') as tel:\n","        pickle.dump(train_data, trd)\n","        pickle.dump(train_labels, trl)\n","        pickle.dump(test_data, ted)\n","        pickle.dump(test_labels, tel)\n","      print(f\"pickle files generated: {train_data = } {train_labels = } {test_data = } {test_labels = }\")\n","\n","    except Exception as e:\n","      print(f\"An unexpected error occurred: {e}\")\n","    return train_data, train_labels, test_data, test_labels\n"]},{"cell_type":"markdown","source":["This demonstrates how to use the load_video_dataset function to load and preprocess video data from a dataset located at dataset_path. The function utilizes the predefined dataset configurations specified in dataset_configs.\n","\n","The function creates training and testing splits (X_train, Y_train, X_test, Y_test) based on the specified TRAIN_SPLIT parameter (80% training, 20% testing). It preprocesses the video frames according to the provided configurations, including resizing to 224x224 pixels, extracting 15 frames per set, aiming for 5 frames per second, and performing cropping to remove black bars.\n","\n","If the dataset is missing, the function creates it (create_on_missing=True). Finally, the function returns the training and testing data splits for further use in model training and evaluation."],"metadata":{"id":"zVBg6tBgPAyk"}},{"cell_type":"code","source":["dataset_configs = {\n","  'SIZE':  224,\n","  'FRAMES':  15,\n","  'TRAIN_SPLIT':  0.8,\n","  'FPS':  5,\n","  'CROP':  True\n","}\n","\n","ROOT_PATH = 'drive/MyDrive/Piras_Quint_Volpi'\n","dataset_path = f'{ROOT_PATH}/Dataset originale'\n","\n","X_train, Y_train, X_test, Y_test = create_video_dataset(dataset_path, dataset_configs, 'default')"],"metadata":{"id":"hqR-kHn8MxHZ"},"execution_count":null,"outputs":[]}]}